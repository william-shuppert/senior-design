{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import traceback\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose model\n",
    "There are 17 key points in each model, but if one of the key points is not visible, the model just makes an educated guess. I believe that Will had the key points labeled correctly as the nose, eyes, ears, shoulders, elbows, wrists, hips, knees, and ankles. I chose to have my model not only plot the key points, but also output them so that we can have a better understanding of what the model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/aidan/Desktop/Senior design/senior-design/core/testImage.jpg: 384x640 1 person, 720.1ms\n",
      "Speed: 2.8ms preprocess, 720.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([633.2852, 212.6786])\n",
      "tensor([628.8334, 201.9050])\n",
      "tensor([619.6083, 213.4925])\n",
      "tensor([631.9985, 211.0657])\n",
      "tensor([613.4843, 242.4118])\n",
      "tensor([662.2421, 239.3922])\n",
      "tensor([637.2760, 296.2173])\n",
      "tensor([610.3989, 170.1040])\n",
      "tensor([633.3550, 362.6978])\n",
      "tensor([572.7612,  64.7303])\n",
      "tensor([630.1616, 462.3123])\n",
      "tensor([731.4772, 412.5997])\n",
      "tensor([676.5093, 435.6095])\n",
      "tensor([826.9346, 491.5668])\n",
      "tensor([570.1587, 527.4764])\n",
      "tensor([840.9533, 593.6512])\n",
      "tensor([406.8344, 624.2863])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creates the pose model and inputs the image\n",
    "model = YOLO('yolov8m-pose.pt')\n",
    "results = model('testImage.jpg')\n",
    "\n",
    "#plots the key points on the image and creates a new image from it\n",
    "frame = results[0].plot()\n",
    "cv2.imshow(\"YOLOv8 Inference\", frame)\n",
    "\n",
    "keypoints = results[0].keypoints.xy[0]\n",
    "for keypoint in keypoints : print(keypoint)\n",
    "\n",
    "#waits until the user hits any key to close the image\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
