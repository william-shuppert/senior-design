{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import traceback\n",
    "import numpy as np\n",
    "import csv\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data\n",
    "\n",
    "The following is the function that will be used later to process and label each frame in a given video and upload the data to an output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAndClassifyFrames(videoPath, outputFile, classification):\n",
    "    \"\"\"\n",
    "    Process each frame of a given video, extracting pose data using MediaPipe Pose,\n",
    "    and appends the pose data along with a specified classification to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - videoPath (str): The path to the video file.\n",
    "    - outputFile (str): The path to the CSV file where pose data will be appended.\n",
    "    - classification (str): The specified classification associated with each frame.\n",
    "\n",
    "    Note:\n",
    "    - Ensure that the video frames are aligned with the given classification.\n",
    "\n",
    "    Example:\n",
    "    >>> processAndClassifyFrames('video.mp4', 'output.csv', 'walking')\n",
    "\n",
    "    \"\"\"\n",
    "    with open(outputFile, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        cap = cv2.VideoCapture(videoPath)\n",
    "\n",
    "        with mp_pose.Pose(min_detection_confidence=.5, min_tracking_confidence=.5) as pose:\n",
    "            try:\n",
    "                # Loop through the video frames\n",
    "                while cap.isOpened():\n",
    "                    success, frame = cap.read() # Read a frame from the video\n",
    "                    if not success: break\n",
    "\n",
    "                    # Get pose data and export to file\n",
    "                    results = pose.process(frame)\n",
    "                    if (results.pose_landmarks):\n",
    "                        keypoints = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "                        keypoints.insert(0, classification)\n",
    "                        writer.writerow(keypoints)\n",
    "\n",
    "            except Exception as err:\n",
    "                traceback.print_exc()\n",
    "            finally:\n",
    "                # Release the video capture object and close the display window\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The variable outputFile is the destination file where the processed data and classification will be stored.\n",
    "* model_path is the destination where the model weights will be saved after training is complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFile = \"training-data.csv\"\n",
    "model_path = \"action_classifier_weights.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates the required headers for the output file and overrides any previous data with said header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and write header to output file\n",
    "landmarks = ['class']\n",
    "for val in range(1, 33+1): # 33 keypoints\n",
    "    landmarks += [s + str(val) for s in 'xyzv']\n",
    "\n",
    "with open(outputFile, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process And Classify Video Frames\n",
    "The provided code snippet serves the purpose of processing and classifying video frames, with the ability to customize the video source and the classification category. It appends the resulting data to an output file specified within the code. This should be run for every video/classification in the dataset.\n",
    "\n",
    "* The variable videoPath is set to a specific file path which points to the video to be processed.\n",
    "* The variable classification indicates the specific category or class by which each frame in the video will be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoPath = \"C:\\\\Users\\\\Will\\\\Downloads\\\\pushup.MOV\"\n",
    "classification = \"pushup\"\n",
    "\n",
    "processAndClassifyFrames(videoPath, outputFile, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classification Model\n",
    "Here, we set up the train-test split from the data collected previously. We define multiple machine learning pipelines, each combining data scaling using StandardScaler and a different classification algorithm (Logistic Regression, Ridge Classifier, Random Forest, Gradient Boosting, K-Nearest Neighbors, Linear Support Vector Classifier, and Stochastic Gradient Descent Classifier) and then fit the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Will\\anaconda3\\envs\\senior-design\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(outputFile)\n",
    "\n",
    "X = df.drop('class', axis=1) # features\n",
    "y = df['class'] # classifications\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.35, random_state=101)\n",
    "\n",
    "pipelines = {\n",
    "    'lr': make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc': make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf': make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb': make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "    'nn': make_pipeline(StandardScaler(), KNeighborsClassifier()),\n",
    "    'svc': make_pipeline(StandardScaler(), LinearSVC()),\n",
    "    'sgd': make_pipeline(StandardScaler(), SGDClassifier()),\n",
    "}\n",
    "\n",
    "fit_models = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    fit_models[name] = pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Models\n",
    "\n",
    "Here we evaluate each models accuracy and visualize it's corresponding confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = {}\n",
    "\n",
    "for algo, model in fit_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    confusion_matrices[algo] = confusion_matrix(y_test, y_pred)\n",
    "    print(algo,\n",
    "        accuracy_score(y_test.values, y_pred),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up a grid of subplots for each confusion matrix\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle(\"Confusion Matrices\", fontsize=16)\n",
    "\n",
    "for i, (name, cm) in enumerate(confusion_matrices.items()):\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=ax)\n",
    "    ax.set_title(f\"Confusion Matrix for {name}\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save/Export Model\n",
    "\n",
    "Now we save the weights for our best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(fit_models['svc'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model\n",
    "\n",
    "Here we can test the model in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path, 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=.5, min_tracking_confidence=.5) as pose:\n",
    "    try:\n",
    "        # Loop through the video frames\n",
    "        while cap.isOpened():\n",
    "            # Read a frame from the video\n",
    "            success, frame = cap.read()\n",
    "\n",
    "            if not success: break\n",
    "\n",
    "            # Run inference on the frame\n",
    "            results = pose.process(frame)\n",
    "\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "                keypoints = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "                X = pd.DataFrame([keypoints], columns=landmarks[1:])\n",
    "                class_ = model.predict(X)[0]\n",
    "                cv2.putText(frame, class_, (95, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(frame, class_, (95, 40), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,0,0), 2, cv2.LINE_AA)\n",
    "            \n",
    "            \n",
    "            cv2.imshow(\"\", frame)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    except Exception as err:\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        # Release the video capture object and close the display window\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senior-design",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
